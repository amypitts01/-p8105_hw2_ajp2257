p8105 HW2
================
Amy Pitts
9/30/2020

# Problem 1

##### This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.

##### Read and clean the Mr. Trash Wheel sheet:

  - specify the sheet in the Excel file and to omit non-data entries
    (rows with notes / figures; columns containing notes) using
    arguments in read\_excel
  - use reasonable variable names
  - omit rows that do not include dumpster-specific data
  - round the number of sports balls to the nearest integer and converts
    the result to an integer variable (using as.integer)

##### Read and clean precipitation data for 2017 and 2018. For each, omit rows without precipitation data and add a variable year. Next, combine precipitation datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

##### Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2018? What was the median number of sports balls in a dumpster in 2017?

``` r
#mr_trash_wheel = readxl::read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx") 
```

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    range = cell_cols("A:N"))  %>% # only looking at the specific columns
  janitor::clean_names() %>% #cleaning names 
  drop_na(dumpster)  %>% # only looking at the dumster variable 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Reading in the precipitation data

``` r
precip_2018 =
  read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
     sheet = "2018 Precipitation",
     skip = 1
  ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 =
  read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
     sheet = "2017 Precipitation",
     skip = 1
  ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

now combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2017, precip_2018)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2017     1  2.34 January   
    ##  2  2017     2  1.46 February  
    ##  3  2017     3  3.57 March     
    ##  4  2017     4  3.99 April     
    ##  5  2017     5  5.64 May       
    ##  6  2017     6  1.4  June      
    ##  7  2017     7  7.09 July      
    ##  8  2017     8  4.44 August    
    ##  9  2017     9  1.95 September 
    ## 10  2017    10  0    October   
    ## # … with 14 more rows

This data set contains info from the Mr. Trashwheel trash collector in
Baltimore Maryland. As trash enters the inner harbor, the trashwheel
collects that trash and stores it in a dumster. The dataset contains
info on year month and trash collected including some specific kinds of
trash. There are a total of 344 rows in our final dataset. Addition data
sheets include monthly precipitation data.

# Problem 2

##### This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC.

``` r
transit_df = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols(
                      .default = col_character(),
                      `Station Latitude` = col_double(),
                      `Station Longitude` = col_double(),
                      #I am forcing these routes to be chars  
                      Route8 = col_character(), 
                      Route9 = col_character(),
                      Route10 = col_character(),
                      Route11 = col_character(),
                      ADA = col_logical(),
                      `Free Crossover` = col_logical(),
                      `Entrance Latitude` = col_double(),
                      `Entrance Longitude` = col_double() 
                      )) %>% 
              janitor::clean_names()  %>% 
              mutate(
                entry = ifelse(entry == "YES", TRUE, FALSE ),
                vending = ifelse(vending == "YES", TRUE, FALSE )
              )
```

##### Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

``` r
names(transit_df)
```

    ##  [1] "division"           "line"               "station_name"      
    ##  [4] "station_latitude"   "station_longitude"  "route1"            
    ##  [7] "route2"             "route3"             "route4"            
    ## [10] "route5"             "route6"             "route7"            
    ## [13] "route8"             "route9"             "route10"           
    ## [16] "route11"            "entrance_type"      "entry"             
    ## [19] "exit_only"          "vending"            "staffing"          
    ## [22] "staff_hours"        "ada"                "ada_notes"         
    ## [25] "free_crossover"     "north_south_street" "east_west_street"  
    ## [28] "corner"             "entrance_latitude"  "entrance_longitude"
    ## [31] "station_location"   "entrance_location"

``` r
skimr::skim(transit_df)
```

|                                                  |             |
| :----------------------------------------------- | :---------- |
| Name                                             | transit\_df |
| Number of rows                                   | 1868        |
| Number of columns                                | 32          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |             |
| Column type frequency:                           |             |
| character                                        | 24          |
| logical                                          | 4           |
| numeric                                          | 4           |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |             |
| Group variables                                  | None        |

Data summary

**Variable type: character**

| skim\_variable       | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| division             |          0 |           1.00 |   3 |   3 |     0 |         3 |          0 |
| line                 |          0 |           1.00 |   5 |  17 |     0 |        36 |          0 |
| station\_name        |          0 |           1.00 |   4 |  39 |     0 |       356 |          0 |
| route1               |          0 |           1.00 |   1 |   2 |     0 |        24 |          0 |
| route2               |        848 |           0.55 |   1 |   2 |     0 |        20 |          0 |
| route3               |       1374 |           0.26 |   1 |   2 |     0 |        18 |          0 |
| route4               |       1547 |           0.17 |   1 |   1 |     0 |        13 |          0 |
| route5               |       1630 |           0.13 |   1 |   1 |     0 |        12 |          0 |
| route6               |       1741 |           0.07 |   1 |   1 |     0 |         7 |          0 |
| route7               |       1788 |           0.04 |   1 |   2 |     0 |         7 |          0 |
| route8               |       1820 |           0.03 |   1 |   1 |     0 |         3 |          0 |
| route9               |       1840 |           0.01 |   1 |   1 |     0 |         2 |          0 |
| route10              |       1845 |           0.01 |   1 |   1 |     0 |         1 |          0 |
| route11              |       1845 |           0.01 |   1 |   1 |     0 |         1 |          0 |
| entrance\_type       |          0 |           1.00 |   4 |   9 |     0 |         7 |          0 |
| exit\_only           |       1812 |           0.03 |   3 |   3 |     0 |         1 |          0 |
| staffing             |          0 |           1.00 |   4 |   6 |     0 |         4 |          0 |
| staff\_hours         |       1828 |           0.02 |  16 |  33 |     0 |        16 |          0 |
| ada\_notes           |       1793 |           0.04 |   5 |  17 |     0 |        10 |          0 |
| north\_south\_street |         29 |           0.98 |   4 |  23 |     0 |       307 |          0 |
| east\_west\_street   |         35 |           0.98 |   6 |  24 |     0 |       352 |          0 |
| corner               |         32 |           0.98 |   1 |   4 |     0 |         8 |          0 |
| station\_location    |          0 |           1.00 |  20 |  23 |     0 |       472 |          0 |
| entrance\_location   |          0 |           1.00 |  22 |  23 |     0 |      1857 |          0 |

**Variable type: logical**

| skim\_variable  | n\_missing | complete\_rate | mean | count               |
| :-------------- | ---------: | -------------: | ---: | :------------------ |
| entry           |          0 |              1 | 0.94 | TRU: 1753, FAL: 115 |
| vending         |          0 |              1 | 0.90 | TRU: 1685, FAL: 183 |
| ada             |          0 |              1 | 0.25 | FAL: 1400, TRU: 468 |
| free\_crossover |          0 |              1 | 0.78 | TRU: 1448, FAL: 420 |

**Variable type: numeric**

| skim\_variable      | n\_missing | complete\_rate |    mean |   sd |      p0 |     p25 |     p50 |     p75 |    p100 | hist  |
| :------------------ | ---------: | -------------: | ------: | ---: | ------: | ------: | ------: | ------: | ------: | :---- |
| station\_latitude   |          0 |              1 |   40.73 | 0.07 |   40.58 |   40.69 |   40.73 |   40.77 |   40.90 | ▂▅▇▃▂ |
| station\_longitude  |          0 |              1 | \-73.94 | 0.06 | \-74.03 | \-73.99 | \-73.96 | \-73.91 | \-73.76 | ▇▆▃▂▁ |
| entrance\_latitude  |          0 |              1 |   40.73 | 0.07 |   40.58 |   40.69 |   40.73 |   40.77 |   40.90 | ▂▅▇▃▂ |
| entrance\_longitude |          0 |              1 | \-73.86 | 3.42 | \-74.03 | \-73.99 | \-73.96 | \-73.91 |   73.99 | ▇▁▁▁▁ |

#### Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

The transit dataset has 1868 rows and 32 columns all describing subway
lines of NYC. If has information such as the subway line, the subways
that go to the station, the location, the staffing situation, and much
more relevant informtation about the subways platforms. My cleaning
process has been cleaning up the names of all the variables and then
forcing the route\# to all be characters. This way everything is
consistent and makes sense. I also checked to make sure that the
read\_csv was correctly identifying all the variable types and it was
except for the route numbers greater than 9. I also convirted all the
yes no variables (entry and vending) to true and false.

##### Answer the following questions using these data:

  - How many distinct stations are there? Note that stations are
    identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1;
    125st 4/5); the distinct function may be useful here.

<!-- end list -->

``` r
unique_stations = transit_df %>% select(station_name, route1, route2,  route3,  
                                        route4, route5, route6, route7, route8, 
                                        route9, route10, route11) %>% 
                                 distinct() %>%
                                 count()
```

There are 456 unique stations\!

  - How many stations are ADA compliant?

<!-- end list -->

``` r
transit_df %>% 
  select(ada) %>% 
  table()
```

    ## .
    ## FALSE  TRUE 
    ##  1400   468

There are 468 records that are ADA compliant meaning that 468 stations
are compliant in this dataset.

  - What proportion of station entrances / exits without vending allow
    entrance?

<!-- end list -->

``` r
transit_df %>% 
  select(entry, vending) %>% 
  table()
```

    ##        vending
    ## entry   FALSE TRUE
    ##   FALSE   114    1
    ##   TRUE     69 1684

There is a total of 183 stations that do not have vending and within
those 183 stations only 69 allow entrance. Thus this proportion of the
stations that allow entry / stations that have no vending is 69 / 183 =
0.377 = 37%. However, out of all that stations there are 69 that do not
have vending but allow entrance so the proprtion out of all the stations
is = no vending but allowed entry / total number of stations = 69/ 1868
= 0.0369 = 3.7%

##### Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

``` r
# re formating the data 
transit_df_tidy = 
  pivot_longer(
    transit_df, 
    route1:route11,
    names_to = "route", 
    names_prefix = "route",
    values_to = "route_name") %>% 
  drop_na(route_name) #removing the NA values 

#Filtering for A train, looking at only distinct, counting them all up 
distinct_A <- filter(transit_df_tidy, route_name=="A") %>%
  distinct() %>%
  count()
distinct_A
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   273

There are 273 distinct stations that have access to the A line.

``` r
#Filtering for A train and for ADA compliance 
distinct_ada = filter(transit_df_tidy, route_name=="A", ada == TRUE) %>%
  count()
distinct_ada
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   107

There are 107 stations that have the A train that are ADA compliant.

# Problem 3

##### This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

##### First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez\_dem and prez\_gop; and remove the day variable.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_month = read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
                janitor::clean_names() %>%
                separate(mon, sep="-", into = c("year", "month", "day")) %>%
                mutate(
                 year = as.integer(year),
                 month = as.integer(month),
                 day = as.integer(day)
                ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month = left_join(pols_month, month_df, by = "month") %>% 
              relocate(year, month_name) %>% #i want the month values closer to front
              mutate(
                 prez_dem = ifelse(prez_dem == 1, TRUE, NA), #puting NA so we can easily drop later
                 prez_gop = ifelse(prez_gop == 1, TRUE, NA) 
              ) 
              
pols_month = pivot_longer( # diretion said to combine the dem and gop prez data
                pols_month, 
                c(prez_dem, prez_gop), 
                names_to = "president", 
                names_prefix = "prez_",
                values_to = "pres_data") %>% 
                drop_na(pres_data) %>% #removing the NA values 
                select(-pres_data) %>% #no longer need the pres_data column becuase it is redundent
                select(-c(day, month)) #directions said to remove day column and month is redundent
```

This dataset contains 817 entries and with 9 different columns all
related to the politicians who are democratic or republican. We have
arranged the data in a way so the year and month is easily reable as
well as what polictical party the politician belongs too.

##### Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

``` r
snp_df = read_csv(file = "./data/fivethirtyeight_datasets/snp.csv")  %>%
                janitor::clean_names() %>%
                separate(date, sep="/", into = c("day", "month", "year")) %>%
                mutate(
                 year = as.integer(year),
                 month = as.integer(month),
                 day = as.integer(day)
                ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp_df = left_join(snp_df, month_df, by = "month") %>% 
              relocate(year, month_name) %>% #rearranging the variables 
              select(-c(month)) # the month value is repetitive so removing 
```

This data set snf\_df has 787 entries and 4 different variable columns.
It has data related to the stock market index (S\&P). The close column
relates to what the value of the S\&P index was at the end of the day.
The other information relates to the date.

##### Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

``` r
unemploy = read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv")  %>%
          janitor::clean_names() 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemploy = pivot_longer(
  unemploy, 
  jan:dec,
  names_to = "month",
  values_to = "unemployment_rate")

month_word = 
  tibble(
    month = c("jan", "feb", "mar", "apr", "may", "jun",
              "jul", "aug", "sep", "oct", "nov", "dec"),
    month_name = month.name
  )
unemploy = left_join(unemploy, month_word, by = "month") %>% 
              relocate(year, month_name) %>%
              select(-month)
```

This dataset has 816 entries and 3 different variable columns. The
original dataset seperated the unemployment rate by the month but this
new cleaned up dataframe has info on the year, month, and the for each
year and month it gives the unemployment rate.

##### Join the datasets by merging snp into pols, and merging unemployment into the result.

``` r
#first merging snp into pols 
joining_df = left_join(snp_df, pols_month, by=c("year","month_name"))
total_df = left_join(joining_df, unemploy, by=c("year","month_name"))
head(total_df)
```

    ## # A tibble: 6 x 12
    ##    year month_name   day close gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##   <dbl> <chr>      <int> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ## 1  2015 January        7 2080.      31      54     245      18      44     188
    ## 2  2015 January        6 2063.      31      54     245      18      44     188
    ## 3  2015 January        5 2107.      31      54     245      18      44     188
    ## 4  2015 January        4 2086.      31      54     245      18      44     188
    ## 5  2015 February       3 2068.      31      54     245      18      44     188
    ## 6  2015 February       2 2104.      31      54     245      18      44     188
    ## # … with 2 more variables: president <chr>, unemployment_rate <dbl>

##### Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

This final dataframe has 787 entries and 12 column variables. It is a
merged table of all the three tables I talked about earlier. The tables
were merged using both the year and the month. It give a look at the
political people in office and if they were democratic or republican and
shows a quick glances at the economy by looking at the stock market
(S\&P) values of each given month/year as well as the unemployment rate.
Looking specificaly at some important variable we first have `year`
which has the years 1950 up to 2015. Other key variables are `close`
which is the (S\&P) close at each day, and the unemployment rate which
is under the variable `unemployment_rate`. Another important variable is
the `president` which states whether the president was a democrat or
republican.
